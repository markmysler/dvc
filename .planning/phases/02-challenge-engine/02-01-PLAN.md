---
phase: 02-challenge-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [
  challenges/definitions/challenges.json,
  engine/orchestrator.py,
  engine/__init__.py,
  engine/requirements.txt,
  challenges/test-challenge/Dockerfile,
  challenges/test-challenge/app.py,
  scripts/challenge-setup.sh,
  README.md
]
autonomous: true

must_haves:
  truths:
    - "System can define challenges with metadata and container specifications"
    - "System can spawn challenge containers with security isolation"
    - "System can list and track running challenge containers"
  artifacts:
    - path: "challenges/definitions/challenges.json"
      provides: "Challenge catalog with metadata and container specs"
      contains: "challenge definitions array"
    - path: "engine/orchestrator.py"
      provides: "Container lifecycle management"
      exports: ["ChallengeOrchestrator", "spawn_challenge", "stop_challenge"]
    - path: "challenges/test-challenge/"
      provides: "Reference challenge implementation"
      contains: "Dockerfile and challenge application"
  key_links:
    - from: "engine/orchestrator.py"
      to: "docker/podman API"
      via: "container runtime calls"
      pattern: "docker\\.from_env\\(\\)|podman.*run"
    - from: "challenges.json"
      to: "engine/orchestrator.py"
      via: "challenge spec loading"
      pattern: "json\\.load.*challenges"
---

<objective>
Implement challenge definition system and container orchestration engine for securely spawning CTF challenge containers.

Purpose: Establish the core infrastructure for launching isolated challenge environments that users can practice vulnerabilities against.
Output: Working challenge engine that can spawn and manage containerized security challenges with proper isolation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-challenge-engine/02-RESEARCH.md
@.planning/phases/01-foundation-security/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create challenge definition system</name>
  <files>challenges/definitions/challenges.json, challenges/test-challenge/Dockerfile, challenges/test-challenge/app.py</files>
  <action>
    Create JSON-based challenge catalog following research patterns. Define schema with fields: id, name, description, difficulty, category, container_spec (image, ports, environment, resource_limits), metadata.

    Create a test challenge "web-basic-xss" as reference implementation:
    - Simple Flask app with intentional XSS vulnerability
    - Dockerfile based on python:3.11-slim with security hardening
    - Challenge app serves vulnerable form and displays flag when exploited
    - Follow research security patterns: read-only filesystem, dropped capabilities, resource limits

    Structure follows research recommendations with challenge type categorization.
  </action>
  <verify>cat challenges/definitions/challenges.json shows valid JSON with test challenge definition; docker build challenges/test-challenge/ succeeds</verify>
  <done>Challenge catalog exists with valid schema and test challenge can be built as container image</done>
</task>

<task type="auto">
  <name>Task 2: Implement container orchestration engine</name>
  <files>engine/orchestrator.py, engine/__init__.py, engine/requirements.txt</files>
  <action>
    Create Python-based orchestrator following research security patterns. Implement ChallengeOrchestrator class with methods:
    - load_challenges(): Parse challenges.json into challenge specs
    - spawn_challenge(challenge_id, user_id): Create isolated container with security hardening (drop ALL caps, read-only filesystem, resource limits, unique network namespace)
    - stop_challenge(container_id): Stop and remove container with cleanup
    - list_running(): Return active challenge containers with metadata

    Use docker-py library for container management. Apply research security configurations: memory limits (256MB), CPU quotas (50% single core), no-new-privileges, tmpfs for /tmp.
    Include comprehensive error handling and logging. Generate unique session IDs for tracking.
  </action>
  <verify>python -c "from engine.orchestrator import ChallengeOrchestrator; c = ChallengeOrchestrator(); print(c.load_challenges())" succeeds</verify>
  <done>Orchestrator can load challenge definitions and implements secure container lifecycle management methods</done>
</task>

<task type="auto">
  <name>Task 3: Create challenge management scripts</name>
  <files>scripts/challenge-setup.sh, README.md</files>
  <action>
    Create bash script for challenge engine operations: setup dependencies (install docker-py, flask), build challenge images, start/stop orchestrator service, verify challenge definitions.

    Add challenge engine commands to README in "Challenge Management" section:
    - ./scripts/challenge-setup.sh - Set up challenge engine
    - python -m engine.orchestrator - Test challenge loading
    - npm run challenge:build - Build challenge images

    Script should check for Docker/Podman availability, install Python dependencies from engine/requirements.txt, validate challenge definitions JSON schema.
    Include integration with existing monitoring setup for challenge container metrics.
  </action>
  <verify>./scripts/challenge-setup.sh runs without errors and installs dependencies</verify>
  <done>Challenge engine setup script exists and integrates with project infrastructure</done>
</task>

</tasks>

<verification>
Test spawning test challenge: `python -c "from engine.orchestrator import ChallengeOrchestrator; c = ChallengeOrchestrator(); result = c.spawn_challenge('web-basic-xss', 'test-user'); print(f'Container: {result}')"`

Challenge container appears in `podman ps` output with security restrictions applied.
</verification>

<success_criteria>
- Challenge definition system exists with valid JSON schema
- Container orchestrator can securely spawn and manage challenge containers
- Test challenge container builds and runs with proper security isolation
- Setup scripts integrate challenge engine with existing project infrastructure
- All security hardening from research is properly applied (dropped capabilities, resource limits, read-only filesystem)
</success_criteria>

<output>
After completion, create `.planning/phases/02-challenge-engine/02-01-SUMMARY.md`
</output>